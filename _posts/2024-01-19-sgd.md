---
layout: post
title:  Stochastic Gradient Descent
---

<div class="message">
  Gradient Descent, Stochastic Gradient Descent, Multi-batch Gradient Descent
</div>

Gradient descent is a method for <a href="https://en.wikipedia.org/wiki/Gradient_descent"> unconstrained mathematical optimization </a>.
The direction of gradient of a function is in the direction of its maximum.
In ML, the idea is to iteratively move in the direction opposite to the gradient, to reach a local minima in the loss landscape.
i.e. 
$$ x_{n+1} = x_n - \gamma \nabla F(x_n) $$



> Comments